{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ebdbb2e-e786-4b40-9e24-75a3fb10ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6eef326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义带两个卷积路径和一条捷径的残差基本块类\n",
    "class BasicBlock(nn.Module):\n",
    "\texpansion = 1\n",
    "\tdef __init__(self, in_planes, planes, stride=1): #初始化函数，in_planes为输入通道数，planes为输出通道数，步长默认为1\n",
    "\t\tsuper(BasicBlock, self).__init__()\n",
    "#定义第一个卷积，默认卷积前后图像大小不变但可修改stride使其变化，通道可能改变\n",
    "\t\tself.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, \t\t\t\tpadding=1, bias=False)\n",
    "#定义第一个批归一化\n",
    "\t\tself.bn1 = nn.BatchNorm2d(planes)\n",
    "#定义第二个卷积，卷积前后图像大小不变，通道数不变\n",
    "\t\tself.conv2 = nn.Conv2d(planes, planes, kernel_size=3,stride=1, padding=1, bias=False)\n",
    "#定义第二个批归一化\n",
    "\t\tself.bn2 = nn.BatchNorm2d(planes)\n",
    "#定义一条捷径，若两个卷积前后的图像尺寸有变化(stride不为1导致图像大小变化或通道数改变)，捷径通过1×1卷积用stride修改大小\n",
    "#以及用expansion修改通道数，以便于捷径输出和两个卷积的输出尺寸匹配相加\n",
    "\t\tself.shortcut = nn.Sequential()\n",
    "\t\tif stride != 1 or in_planes != self.expansion*planes:\n",
    "\t\t\tself.shortcut = nn.Sequential(\n",
    "\t\t\t\tnn.Conv2d(in_planes, self.expansion*planes,kernel_size=1, stride=stride, bias=False),\n",
    "\t\t\t\tnn.BatchNorm2d(self.expansion*planes)\n",
    "\t\t\t)\n",
    "#定义前向传播函数，输入图像为x，输出图像为out\n",
    "\tdef forward(self, x):\n",
    "\t\tout = F.relu(self.bn1(self.conv1(x))) #第一个卷积和第一个批归一化后用ReLU函数激活\n",
    "\t\tout = self.bn2(self.conv2(out))\n",
    "\t\tout += self.shortcut(x) #第二个卷积和第二个批归一化后与捷径相加\n",
    "\t\tout = F.relu(out) #两个卷积路径输出与捷径输出相加后用ReLU激活\n",
    "\t\treturn out\n",
    "#定义残差网络ResNet18\n",
    "class ResNet(nn.Module):\n",
    "#定义初始函数，输入参数为残差块，残差块数量，默认参数为分类数10\n",
    "\tdef __init__(self, block, num_blocks, num_classes=10):\n",
    "\t\tsuper(ResNet, self).__init__()\n",
    "#设置第一层的输入通道数\n",
    "\t\tself.in_planes = 64\n",
    "#定义输入图片先进行一次卷积与批归一化，使图像大小不变，通道数由3变为64得两个操作\n",
    "\t\tself.conv1 = nn.Conv2d(3, 64, kernel_size=3,stride=1, padding=1, bias=False)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(64)\n",
    "#定义第一层，输入通道数64，有num_blocks[0]个残差块，残差块中第一个卷积步长自定义为1\n",
    "\t\tself.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "#定义第二层，输入通道数128，有num_blocks[1]个残差块，残差块中第一个卷积步长自定义为2\n",
    "\t\tself.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "#定义第三层，输入通道数256，有num_blocks[2]个残差块，残差块中第一个卷积步长自定义为2\n",
    "\t\tself.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "#定义第四层，输入通道数512，有num_blocks[3]个残差块，残差块中第一个卷积步长自定义为2\n",
    "\t\tself.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "#定义全连接层，输入512*block.expansion个神经元，输出10个分类神经元\n",
    "\t\tself.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "#定义创造层的函数，在同一层中通道数相同，输入参数为残差块，通道数，残差块数量，步长\n",
    "\tdef _make_layer(self, block, planes, num_blocks, stride):\n",
    "#strides列表第一个元素stride表示第一个残差块第一个卷积步长，其余元素表示其他残差块第一个卷积步长为1\n",
    "\t\tstrides = [stride] + [1]*(num_blocks-1)\n",
    "#创建一个空列表用于放置层\n",
    "\t\tlayers = []\n",
    "#遍历strides列表，对本层不同的残差块设置不同的stride\n",
    "\t\tfor stride in strides:\n",
    "\t\t\tlayers.append(block(self.in_planes, planes, stride)) #创建残差块添加进本层\n",
    "\t\t\tself.in_planes = planes * block.expansion #更新本层下一个残差块的输入通道数或本层遍历结束后作为下一层的输入通道数\n",
    "\t\treturn nn.Sequential(*layers) #返回层列表\n",
    "#定义前向传播函数，输入图像为x，输出预测数据\n",
    "\tdef forward(self, x):\n",
    "\t\tout = F.relu(self.bn1(self.conv1(x))) #第一个卷积和第一个批归一化后用ReLU函数激活\n",
    "\t\tout = self.layer1(out) #第一层传播\n",
    "\t\tout = self.layer2(out) #第二层传播\n",
    "\t\tout = self.layer3(out) #第三层传播\n",
    "\t\tout = self.layer4(out) #第四层传播\n",
    "\t\tout = F.avg_pool2d(out, 4) #经过一次4×4的平均池化\n",
    "\t\tout = out.view(out.size(0), -1) #将数据flatten平坦化\n",
    "\t\tout = self.linear(out) #全连接传播\n",
    "\t\treturn out\n",
    "\n",
    "fine_resnet18 = ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3a0b02a-f7db-4c3f-9414-7abf94d6d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    def __init__(self, output):\n",
    "        self.log_file_name = output\n",
    "    def log(self, message):\n",
    "        print(message)\n",
    "        with open(self.log_file_name, 'a') as f:\n",
    "            f.write(message+'\\n')\n",
    "\n",
    "def get_dataset(dir, name):\n",
    "\n",
    "    if name=='mnist':\n",
    "        train_dataset = datasets.MNIST(dir, train=True, download=True, transform=transforms.ToTensor())\n",
    "        eval_dataset = datasets.MNIST(dir, train=False, transform=transforms.ToTensor())\n",
    "        \n",
    "    elif name=='cifar10':\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "\n",
    "\n",
    "        train_dataset = datasets.CIFAR10(dir, train=True, download=True, transform=transform_train)\n",
    "        eval_dataset = datasets.CIFAR10(dir, train=False, transform=transform_test)\n",
    "\n",
    "\n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "def get_model(name=\"fine\", pretrained=True):\n",
    "    if name == \"fine\":\n",
    "        model = fine_resnet18\n",
    "    elif name == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=pretrained)\n",
    "    elif name == \"resnet50\":\n",
    "        # model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        model = models.resnet50(pretrained=pretrained) \n",
    "    elif name == \"densenet121\":\n",
    "        model = models.densenet121(pretrained=pretrained)        \n",
    "    elif name == \"alexnet\":\n",
    "        model = models.alexnet(pretrained=pretrained)\n",
    "    elif name == \"vgg16\":\n",
    "        model = models.vgg16(pretrained=pretrained)\n",
    "    elif name == \"vgg19\":\n",
    "        model = models.vgg19(pretrained=pretrained)\n",
    "    elif name == \"inception_v3\":\n",
    "        model = models.inception_v3(pretrained=pretrained)\n",
    "    elif name == \"googlenet\":        \n",
    "        model = models.googlenet(pretrained=pretrained)\n",
    "\n",
    "    # device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    return model\n",
    "        \n",
    "\n",
    "def serialize_model(model: torch.nn.Module) -> torch.Tensor:\n",
    "    parameters = [param.data.view(-1) for param in model.parameters()]\n",
    "    m_parameters = torch.cat(parameters)\n",
    "\n",
    "    return m_parameters\n",
    "\n",
    "def deserialize_model(model: torch.nn.Module, serialized_parameters: torch.Tensor, mode=\"copy\"):\n",
    "\n",
    "    current_index = 0  # keep track of where to read from grad_update\n",
    "    for parameter in model.parameters():\n",
    "        \n",
    "        numel = parameter.data.numel()\n",
    "        size = parameter.data.size()\n",
    "        if mode == \"copy\":\n",
    "            parameter.data.copy_(serialized_parameters[current_index:current_index + numel].view(size))\n",
    "        elif mode == \"add\":\n",
    "            parameter.data.add_(serialized_parameters[current_index:current_index + numel].view(size))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid deserialize mode {}, require \\\"copy\\\" or \\\"add\\\" \".format(mode))\n",
    "        current_index += numel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7bd106a-9605-4f15-941f-c0f9e7171f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "\n",
    "    def __init__(self, conf, train_dataset, id = -1):\n",
    "        \n",
    "        self.conf = conf\n",
    "        self.local_model = get_model(self.conf[\"model_name\"]) \n",
    "        self.id = id\n",
    "        self.train_dataset = train_dataset\n",
    "        \n",
    "        all_range = list(range(len(self.train_dataset)))\n",
    "        data_len = int(len(self.train_dataset) / self.conf['no_clients'])\n",
    "        train_indices = all_range[id * data_len: (id + 1) * data_len]\n",
    "        # logger.log(\"client: %d dataset len %d\" %(id, data_len))\n",
    "                \n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=conf[\"batch_size\"], sampler=SubsetRandomSampler(train_indices))\n",
    "        \n",
    "        \n",
    "    def local_train(self, global_model):\n",
    "\n",
    "        # Download global model to client\n",
    "        for name, param in global_model.state_dict().items():\n",
    "            self.local_model.state_dict()[name].copy_(param.clone())\n",
    "        \n",
    "        # Initialize the loss function\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        if self.conf['opt'] == 'sgd':\n",
    "          optimizer = torch.optim.SGD(self.local_model.parameters(), lr=self.conf['lr'], momentum=self.conf['momentum'], weight_decay=self.conf['weight_decay'], nesterov=\"nesterov\" in conf['opt'])\n",
    "        elif self.conf['opt'] == 'rmsprop':\n",
    "          optimizer = torch.optim.RMSprop(self.local_model.parameters(), lr=self.conf['lr'], momentum=self.conf['momentum'], weight_decay=self.conf['weight_decay'])\n",
    "        elif self.conf['opt'] == 'adam':\n",
    "          optimizer = torch.optim.Adam(self.local_model.parameters(), lr=self.conf['lr'], weight_decay=self.conf['weight_decay'])\n",
    "        elif self.conf['opt'] == 'adamw':\n",
    "          optimizer = torch.optim.AdamW(self.local_model.parameters(), lr=self.conf['lr'], weight_decay=self.conf['weight_decay'])\n",
    "        elif self.conf['opt'] == 'nadam':\n",
    "          optimizer = torch.optim.NAdam(self.local_model.parameters(), lr=self.conf['lr'], weight_decay=self.conf['weight_decay'])\n",
    "        elif self.conf['opt'] == 'radam':\n",
    "          optimizer = torch.optim.RAdam(self.local_model.parameters(), lr=self.conf['lr'], weight_decay=self.conf['weight_decay'])\n",
    "\n",
    "        # size = len(self.train_loader.dataset)\n",
    "        \n",
    "        self.local_model.train()\n",
    "        # device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        for e in range(self.conf[\"local_epochs\"]):      \n",
    "            for inputs, lables in self.train_loader:\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = inputs.cuda()\n",
    "                    lables = lables.cuda()\n",
    "\n",
    "                # inputs.to(device)\n",
    "                # lables.to(device)\n",
    "                \n",
    "                # Compute prediction and loss\n",
    "                pred = self.local_model(inputs)\n",
    "                loss = loss_fn(pred, lables)\n",
    "                \n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                                \n",
    "                #if batch_id % 100 == 0:\n",
    "                    #loss, current = loss.item(), batch_id * len(data)\n",
    "            if self.conf['no_clients'] <= 5:\n",
    "                logger.log(f\"Begine{self.id+1:>d} | loss: {loss:>7f}  [{self.id+1:>d}/{self.conf['no_clients']:>d}]\")\n",
    "\n",
    "        # update = torch.sub(serialize_model(self.local_model), serialize_model(global_model))\n",
    "        update = serialize_model(self.local_model)\n",
    "        return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de12bd91-cc6e-4b94-b563-45ba9512f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server(object):\n",
    "    \n",
    "    def __init__(self, conf, eval_dataset):\n",
    "    \n",
    "        self.conf = conf \n",
    "        self.global_model = get_model(self.conf[\"model_name\"])\n",
    "        self.eval_loader = DataLoader(eval_dataset, batch_size=self.conf[\"batch_size\"], shuffle=True)\n",
    "        \n",
    "    def get_mal_updates(self, updates):\n",
    "        \n",
    "        attack_type = self.conf['attack_type']\n",
    "        agg_type = self.conf['agg_type']\n",
    "        m = self.conf['no_attackers']\n",
    "        p = self.conf['pertubation']\n",
    "         \n",
    "        serialzed_updates = torch.stack(updates)\n",
    "        avg = torch.mean(serialzed_updates, 0)\n",
    "        \n",
    "        if p == 'unit':\n",
    "            deviation = avg / torch.norm(avg)\n",
    "        elif p == 'sign':\n",
    "            deviation = torch.sign(avg)\n",
    "        elif p == 'std':\n",
    "            deviation = torch.std(serialzed_updates)\n",
    "          \n",
    "        if attack_type == \"None\":\n",
    "            mal_updates = updates\n",
    "        elif attack_type == \"lie\":\n",
    "            mal_updates = lie_attack(updates, m)\n",
    "        elif attack_type == \"fang\":\n",
    "            mal_updates = fang_attack(updates, m, avg, agg_type)\n",
    "        elif attack_type == \"optim\":\n",
    "            mal_updates = optim_attack(updates, m, avg, deviation, agg_type)\n",
    "        elif attack_type == \"optim_min_max\":\n",
    "            mal_updates = optim_min(updates, m, avg, deviation, min='max')\n",
    "        elif attack_type == \"optim_min_sum\":\n",
    "            mal_updates = optim_min(updates, m, avg, deviation, min='sum')\n",
    "            \n",
    "        return mal_updates\n",
    "                              \n",
    "    def model_aggregate(self, updates):\n",
    "        \n",
    "        agg_type = self.conf['agg_type']\n",
    "        m = self.conf['no_attackers']\n",
    "        serialzed_updates = torch.stack(updates)  \n",
    "\n",
    "        if agg_type == \"fedavg\":\n",
    "            agg_update = torch.mul(torch.sum(serialzed_updates, 0), self.conf['lambda'])\n",
    "        elif agg_type == \"median\":\n",
    "            agg_update = torch.median(serialzed_updates, 0)[0]\n",
    "        elif agg_type == \"mean\":\n",
    "            agg_update = torch.mean(serialzed_updates, 0)\n",
    "        elif agg_type == \"krum\":\n",
    "            candidates = krum(updates, m)\n",
    "            agg_update = torch.mean(torch.stack(list(candidates.values())), 0)\n",
    "            logger.log(list(candidates.keys()))\n",
    "        elif agg_type == \"mkrum\":\n",
    "            candidates = krum(updates, m, mkrum=True)\n",
    "            agg_update = torch.mean(torch.stack(list(candidates.values())), 0)\n",
    "            logger.log(list(candidates.keys()))\n",
    "        elif agg_type == \"trmean\":\n",
    "            agg_update = trmean(updates, m)\n",
    "        elif agg_type == \"bulyan\":\n",
    "            agg_update = bulyan(updates, m)\n",
    "\n",
    "        deserialize_model(self.global_model, agg_update)\n",
    "        \n",
    "    def model_eval(self):\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.global_model.eval()\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        size = len(self.eval_loader.dataset)           \n",
    "        num_batches  = len(self.eval_loader)\n",
    "        test_loss, correct = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, lables in self.eval_loader:\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = inputs.cuda()\n",
    "                    lables = lables.cuda()\n",
    "\n",
    "                # X.to(device)\n",
    "                # y.to(device)\n",
    "                pred = self.global_model(inputs)\n",
    "                test_loss += loss_fn(pred, lables).item()\n",
    "                correct += (pred.argmax(1) == lables).type(torch.float).sum().item()\n",
    "        \n",
    "        correct /= size\n",
    "        test_loss /= num_batches\n",
    "        return correct, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85c9bc81-3a85-49da-bec3-0659b9af6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lie_attack(updates, m):\n",
    "    z = {1: 0.68, 3:0.69847, 5:0.7054, 8:0.71904, 10:0.72575, 12:0.73891}\n",
    "    \n",
    "    serialzed_updates = torch.stack(updates)\n",
    "    avg = torch.mean(serialzed_updates, 0)\n",
    "    std = torch.std(serialzed_updates)\n",
    "    \n",
    "    mal_update = avg + z[m] * std\n",
    "    mal_updates = [mal_update] * m + updates\n",
    "        \n",
    "    return mal_updates\n",
    "    \n",
    "def fang_attack(updates, m, avg, agg_type):\n",
    "\n",
    "    serialzed_updates = torch.stack(updates)\n",
    "    deviation = torch.sign(avg)\n",
    "    # Note that Fang attacks on Multi-krum and Bulyan are the same\n",
    "    if agg_type in [\"krum\", \"mkrum\", \"bulyan\"]:\n",
    "    \n",
    "        \n",
    "    \n",
    "        n, d = serialzed_updates.shape\n",
    "    \n",
    "        for update in updates:\n",
    "            dist = torch.norm((updates - update), dim=1)\n",
    "            dists = dist[None, :] if not len(dists) else torch.cat((dists, dist[None, :]), 0)\n",
    "        \n",
    "        dists[dists == 0] = 10000\n",
    "        dists = torch.sort(dists, dim=1)[0]\n",
    "        scores = torch.sum(dists[:, :n - 2 - m], dim=1)\n",
    "        min_score = torch.min(scores)\n",
    "\n",
    "    \n",
    "        term_1 = min_score / ((n - m - 1) * torch.sqrt(torch.Tensor([d]))[0])\n",
    "        max_wre_dist = torch.max(torch.norm((serialzed_updates - avg), 1)) / (torch.sqrt(torch.Tensor([d]))[0])\n",
    "    \n",
    "        lamda = term_1 + max_wre_dist\n",
    "        threshold = 1e-5\n",
    "    \n",
    "        while lamda > threshold:\n",
    "            mal_update = (- lamda * deviation)\n",
    "            mal_updates = mal_update * m + updates\n",
    "        \n",
    "            candidates = krum(updates, m)\n",
    "        \n",
    "            if np.array(candidates) < m:\n",
    "                return mal_updates\n",
    "        \n",
    "            lamda *= 0.5\n",
    "        \n",
    "        if not len(mal_updates):\n",
    "            # logger.log(lamda, threshold)\n",
    "            mal_update = (avg - lamda * deviation)\n",
    "        \n",
    "            mal_updates = [mal_update] * m + updates\n",
    "        \n",
    "        return mal_updates\n",
    "    \n",
    "    # Note that Fang attacks on Trimmed-mean and median are the same\n",
    "    elif agg_type in [\"mean\", \"trmean\", \"median\"]:\n",
    "        # device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        b = 2\n",
    "        max_vector = torch.max(serialzed_updates, 0)[0]\n",
    "        min_vector = torch.max(serialzed_updates, 0)[0]\n",
    "        \n",
    "        max_ = (max_vector > 0).float()\n",
    "        min_ = (min_vector < 0).float()\n",
    "        if torch.cuda.is_available():\n",
    "            max_ = max_.cuda()\n",
    "            min_ = min_.cuda()\n",
    "        # max_ = (max_vector > 0).float().to(device)\n",
    "        # min_ = (min_vector < 0).float().to(device)\n",
    "           \n",
    "        max_[max_ == 1] = b\n",
    "        max_[max_ == 0] = 1 / b\n",
    "        min_[min_ == 1] = b\n",
    "        min_[min_ == 0] = 1 / b\n",
    "\n",
    "        max_range = torch.cat((max_vector[:, None], (max_vector * max_)[:, None]), 1)\n",
    "        min_range = torch.cat(((min_vector * min_)[:, None], min_vector[:, None]), 1)\n",
    "\n",
    "        # rand = torch.rand(len(deviation), m).to(device)\n",
    "        rand = torch.rand(m, len(deviation))\n",
    "        if torch.cuda.is_available():\n",
    "            rand = rand.cuda()\n",
    "        \n",
    "        for i in range(m):\n",
    "            max_rand = max_range[:, 0] + rand[i] * (max_range[:, 1] - max_range[:, 0])\n",
    "            min_rand = min_range[:, 0] + rand[i] * (min_range[:, 1] - min_range[:, 0])\n",
    "            mal_update = (deviation > 0).float()* (max_rand + min_rand)\n",
    "            mal_updates = [mal_update] + updates\n",
    "        \n",
    "        return mal_updates\n",
    "    \n",
    "    else:\n",
    "        return updates\n",
    "\n",
    "def optim_attack(updates, m, avg, dev, agg_type):\n",
    "    # device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    if agg_type in [\"krum\", \"mkrum\", \"bulyan\"]:\n",
    "        # lamda = torch.Tensor([3.0]).to(device)\n",
    "        lamda = torch.Tensor([3.0])\n",
    "\n",
    "    elif agg_type in [\"mean\", \"median\", \"trmean\"]:\n",
    "        # lamda = torch.Tensor([10.0]).to(device)\n",
    "        lamda = torch.Tensor([10.0])\n",
    "    if torch.cuda.is_available():\n",
    "        lamda = lamda.cuda()\n",
    "    threshold = 1e-5\n",
    "    prev_loss = -1\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    iters = 0\n",
    "    \n",
    "    while torch.abs(lamda_succ - lamda) > threshold:\n",
    "        mal_update = (avg - lamda * dev)\n",
    "        mal_updates = mal_update * m + updates\n",
    "        \n",
    "        # Note that optim attacks on multi-krum and Bulyan aggregations are the same\n",
    "        if agg_type in [\"krum\", \"mkrum\", \"bulyan\"]:\n",
    "            if agg_type == \"krum\":\n",
    "                candidates = krum(mal_updates, m)\n",
    "            else:\n",
    "                candidates = krum(mal_updates, m, mkrum=True)\n",
    "        \n",
    "            if np.sum(np.array(candidates) < m) == m:\n",
    "                lamda_succ = lamda\n",
    "                lamda = lamda + lamda_fail / 2\n",
    "            else:\n",
    "                lamda = lamda - lamda_fail / 2\n",
    "            lamda_fail = lamda_fail / 2\n",
    "        \n",
    "        elif agg_type in [\"mean\", \"median\", \"trmean\"]:\n",
    "            if agg_type == \"trmean\":\n",
    "                agg_update = trmean(mal_updates, m)\n",
    "            elif agg_type == \"median\":\n",
    "                agg_update = torch.median(mal_updates, 0)[0]\n",
    "            elif agg_type == \"mean\":\n",
    "                agg_update = torch.mean(mal_updates, 0)\n",
    "            \n",
    "            loss = torch.norm(agg_update - avg)\n",
    "            \n",
    "            if prev_loss < loss:\n",
    "                lamda_succ = lamda\n",
    "                lamda = lamda + lamda_fail / 2\n",
    "            else:\n",
    "                lamda = lamda - lamda_fail / 2\n",
    "\n",
    "            lamda_fail = lamda_fail / 2\n",
    "            prev_loss = loss\n",
    "        else:\n",
    "            return updates\n",
    "        \n",
    "    mal_update = (avg - lamda_succ * dev)\n",
    "    mal_updates = [mal_update] * m + updates\n",
    "    \n",
    "    return mal_updates    \n",
    "\n",
    "def optim_min(updates, m, avg, dev, min='max'):\n",
    "    # device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    lamda = torch.Tensor([10.0])\n",
    "    if torch.cuda.is_available:\n",
    "        # lamda = torch.Tensor([10.0]).to(device)\n",
    "        lamda = lamda.cuda()\n",
    "    threshold = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    for update in updates:\n",
    "        dist = torch.norm((updates - update), dim=1)\n",
    "        dists = dist[None, :] if not len(dists) else torch.cat((dists, dist[None, :]), 0)\n",
    "        \n",
    "    max_distance = torch.max(dists)\n",
    "    scores = torch.sum(dists, dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    \n",
    "                         \n",
    "    while torch.abs(lamda_succ - lamda) > threshold:\n",
    "        mal_update = (avg - lamda * dev)\n",
    "        distance = torch.norm((updates - mal_update), dim=1)\n",
    "        \n",
    "        if min == 'max':\n",
    "            max_d = torch.max(distance)\n",
    "            \n",
    "            if max_d <= max_distance:\n",
    "                # logger.log('successful lamda is ', lamda)\n",
    "                lamda_succ = lamda\n",
    "                lamda = lamda + lamda_fail / 2\n",
    "            else:\n",
    "                lamda = lamda - lamda_fail / 2\n",
    "            lamda_fail = lamda_fail / 2\n",
    "        elif min == 'sum':\n",
    "            score = torch.sum(distance)\n",
    "        \n",
    "            if score <= min_score:\n",
    "                # logger.log('successful lamda is ', lamda)\n",
    "                lamda_succ = lamda\n",
    "                lamda = lamda + lamda_fail / 2\n",
    "            else:\n",
    "                lamda = lamda - lamda_fail / 2\n",
    "            lamda_fail = lamda_fail / 2\n",
    "\n",
    "    # logger.log(lamda_succ)\n",
    "    mal_update = (avg- lamda_succ * dev)\n",
    "    mal_updates = [mal_update] * m + updates\n",
    "    \n",
    "    return mal_updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "44101c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def krum(updates, m, mkrum=False, bulyan=False):\n",
    "    candidates = {}\n",
    "    dists = {}\n",
    "    # Initalize dist matrix\n",
    "    for i, update in enumerate(updates):\n",
    "        dist = {}\n",
    "        for j, update_ in enumerate(updates):\n",
    "            if j == i:\n",
    "                continue         \n",
    "            dist[j] = torch.dist(update, update_).item()  \n",
    "        dists[i] = dist    \n",
    "    if bulyan:\n",
    "        c = 2 * m\n",
    "    else:\n",
    "        c = 2 * m + 2\n",
    "\n",
    "    while len(dists) > c:\n",
    "        # Find the minimum summed distance to cloesest n-m-2 neighbors\n",
    "        scores = {}\n",
    "        for i, dist in dists.items():\n",
    "            scores[i] = sum(sorted(list(dist.values()), key=lambda x:float(x))[:len(dists) - m - 2])\n",
    "        # sel_ind = sorted(scores.items(), key=lambda x: float(x[1]))[0][0]\n",
    "        # logger.log(scores)\n",
    "        ind = min(scores, key=scores.get)\n",
    "        candidates[ind] = updates[ind]\n",
    "\n",
    "        # Remove the selected update from the dist matrix\n",
    "        del dists[ind]\n",
    "        for dist_ in dists.values():\n",
    "            del dist_[ind]\n",
    "\n",
    "        if not mkrum:\n",
    "            break\n",
    "    \n",
    "        # logger.log(candidates)\n",
    "    logger.log(\"Select %d Malicious updates\" %(np.sum(np.array(candidates)<m)))\n",
    "    return candidates\n",
    "\n",
    "def trmean(updates, m):\n",
    "    serialzed_updates = torch.stack(updates)\n",
    "    sorted_updates = torch.sort(serialzed_updates, 0)[0]\n",
    "    if not m:\n",
    "        agg_update = torch.mean(sorted_updates, 0)\n",
    "    else:\n",
    "        agg_update = torch.mean(sorted_updates[m:-m], 0)\n",
    "    return agg_update\n",
    "\n",
    "def bulyan(updates, m):\n",
    "\n",
    "    candidates = krum(updates, m, mkrum=True, bulyan=True)\n",
    "    agg_update = trmean(list(candidates.values()), m)\n",
    "    return agg_update\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f00e3ce4-ea15-4615-8fa5-a94e740ba1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Model: fine | optimizer: sgd | batch_size: 128\n",
      "Learning rate: 0.010000 | Momentum: 0.900000 | Weight decay: 0.000500\n",
      "Datasets: cifar10 | Train datasets: 50000 | Evaluate datasets: 10000\n",
      "Global epochs: 100 | Local epochs: 1\n",
      "Clients: 5 | Attackers: 1\n",
      "Attack: fang | Aggregation: mean | Pertubation: std\n",
      "\n",
      "\n",
      "Start training at: 2022-07-24 21:39:55.092510\n",
      "Begine1 | loss: 1.734655  [1/5]\n",
      "Begine2 | loss: 1.367931  [2/5]\n",
      "Begine3 | loss: 1.174004  [3/5]\n",
      "Begine4 | loss: 1.224118  [4/5]\n",
      "cuda:0\n",
      "cuda:0\n",
      "cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lithium\\Documents\\dissertation\\FLagg.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=105'>106</a>\u001b[0m     updates\u001b[39m.\u001b[39mappend(update)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=106'>107</a>\u001b[0m \u001b[39mif\u001b[39;00m m \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=107'>108</a>\u001b[0m     uptates \u001b[39m=\u001b[39m server\u001b[39m.\u001b[39;49mget_mal_updates(updates)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=109'>110</a>\u001b[0m server\u001b[39m.\u001b[39mmodel_aggregate(updates)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=110'>111</a>\u001b[0m correct, test_loss \u001b[39m=\u001b[39m server\u001b[39m.\u001b[39mmodel_eval()\n",
      "\u001b[1;32mc:\\Users\\lithium\\Documents\\dissertation\\FLagg.ipynb Cell 9\u001b[0m in \u001b[0;36mServer.get_mal_updates\u001b[1;34m(self, updates)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=28'>29</a>\u001b[0m     mal_updates \u001b[39m=\u001b[39m lie_attack(updates, m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=29'>30</a>\u001b[0m \u001b[39melif\u001b[39;00m attack_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfang\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=30'>31</a>\u001b[0m     mal_updates \u001b[39m=\u001b[39m fang_attack(updates, m, avg, agg_type)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=31'>32</a>\u001b[0m \u001b[39melif\u001b[39;00m attack_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moptim\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=32'>33</a>\u001b[0m     mal_updates \u001b[39m=\u001b[39m optim_attack(updates, m, avg, deviation, agg_type)\n",
      "\u001b[1;32mc:\\Users\\lithium\\Documents\\dissertation\\FLagg.ipynb Cell 9\u001b[0m in \u001b[0;36mfang_attack\u001b[1;34m(updates, m, avg, agg_type)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=90'>91</a>\u001b[0m \u001b[39mprint\u001b[39m(rand\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=91'>92</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=92'>93</a>\u001b[0m     max_rand \u001b[39m=\u001b[39m max_range[:, \u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m rand[i] \u001b[39m*\u001b[39;49m (max_range[:, \u001b[39m1\u001b[39;49m] \u001b[39m-\u001b[39;49m max_range[:, \u001b[39m0\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=93'>94</a>\u001b[0m     min_rand \u001b[39m=\u001b[39m min_range[:, \u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m rand[i] \u001b[39m*\u001b[39m (min_range[:, \u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m min_range[:, \u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lithium/Documents/dissertation/FLagg.ipynb#ch0000007?line=94'>95</a>\u001b[0m     mal_update \u001b[39m=\u001b[39m (deviation \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mfloat()\u001b[39m*\u001b[39m (max_rand \u001b[39m+\u001b[39m min_rand)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    conf = {\n",
    "        'model_name': 'fine',\n",
    "        'datasets': 'cifar10',\n",
    "        'batch_size': 128,\n",
    "        'lr': 0.01,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 5e-4,\n",
    "        'opt': 'sgd',\n",
    "        'no_clients': 5,\n",
    "        'no_attackers': 1,\n",
    "        'agg_type': 'mean',\n",
    "        'attack_type': 'fang',\n",
    "        'pertubation': 'std',\n",
    "        'local_epochs': 1,\n",
    "        'global_epochs': 100,\n",
    "        'k': 3,\n",
    "        'lambda': 0.3,\n",
    "        'chpt_path': './checkpoints/',\n",
    "        'resume': False,\n",
    "        'output': './output/',\n",
    "        # 'eta': 2,\n",
    "        # 'alpha': 1.0,\n",
    "        # 'poison_label': 2,\n",
    "        # 'poisoning_per_batch': 4\n",
    "    }\n",
    "    \n",
    "    test = 0\n",
    "\n",
    "    # agg_type = ['fedavg', 'mean', 'median', 'krum', 'mkrum', 'trmean', 'bulyan']\n",
    "    # attack_type = ['lie', 'fang', 'optim', 'optim_min_max', 'optiom_min_sum']\n",
    "    # pertubation = ['unit', 'sign', 'std']\n",
    "    \n",
    "    n = conf['no_clients']\n",
    "    m = conf['no_attackers']\n",
    "    att_type = conf[\"attack_type\"]\n",
    "    agg_type = conf['agg_type']\n",
    "    p = conf['pertubation']\n",
    "    epochs = conf['global_epochs']\n",
    "\n",
    "    if not os.path.exists(conf['chpt_path']):\n",
    "        os.mkdir(conf['chpt_path'])\n",
    "    if not os.path.exists(conf['output']):\n",
    "        os.mkdir(conf['output'])\n",
    "\n",
    "    chpt_path = conf['chpt_path'] + conf['model_name'] + '_' + conf['datasets'] + '_' + str(n) + '_' + str(m) + '_' + att_type + '_' + agg_type + '_' + p + '.pth'\n",
    "    output = conf['output'] + conf['model_name'] + '_' + conf['datasets'] + '_' + str(n) + '_' + str(m) + '_' + att_type + '_' + agg_type + '_' + p + '.txt'\n",
    "\n",
    "    logger = Logger(output)\n",
    "    # Check the validation of aggregation rule\n",
    "    if m >= 0.5 * n:\n",
    "        logger.log(\"No. of attackers must be less than no. of clients\")\n",
    "        exit()\n",
    "    if agg_type == \"bulyan\":\n",
    "        if n < 4 * m + 3:\n",
    "            logger.log(\"Too much malicious clinets\")\n",
    "            exit()\n",
    "\n",
    "    train_datasets, eval_datasets = get_dataset(\"./data/\", conf[\"datasets\"])\n",
    "    \n",
    "    if not conf['resume']:\n",
    "        logger.log(\"Model: %s | optimizer: %s | batch_size: %d\" %(conf[\"model_name\"], conf[\"opt\"], conf[\"batch_size\"]))\n",
    "        logger.log(\"Learning rate: %f | Momentum: %f | Weight decay: %f\" %(conf[\"lr\"], conf[\"momentum\"], conf[\"weight_decay\"]))\n",
    "        logger.log(\"Datasets: %s | Train datasets: %d | Evaluate datasets: %d\" %(conf[\"datasets\"], len(train_datasets), len(eval_datasets)))\n",
    "        logger.log(\"Global epochs: %d | Local epochs: %d\" %(conf[\"global_epochs\"], conf[\"local_epochs\"]))\n",
    "        logger.log(\"Clients: %d | Attackers: %d\" %(n, m))\n",
    "        logger.log(\"Attack: %s | Aggregation: %s | Pertubation: %s\" %(att_type, agg_type, p))\n",
    "        logger.log(\"\\n\")\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    logger.log(\"Start training at: %s\" %(start))\n",
    "    \n",
    "    # Initialize the server and clients model\n",
    "    server = Server(conf, eval_datasets)\n",
    "\n",
    "    clients = []\n",
    "\n",
    "    for c in range(n - m):\n",
    "        clients.append(Client(conf, train_datasets, c))\n",
    "    \n",
    "\n",
    "    # Set resume to True to load the checkpoint\n",
    "    if conf['resume']:\n",
    "        epoch, server_state_dict = torch.load(chpt_path)\n",
    "        server.global_model.load_state_dict(server_state_dict)\n",
    "        epochs = conf['global_epochs'] - epoch\n",
    "        print(\"Resume training from epoch %d at %s\" %(epoch, datetime.datetime.now()))\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # if e == 25:\n",
    "        #     conf['lr'] = conf['lr'] / 10\n",
    "        # elif e == 50:\n",
    "        #     conf['lr'] = conf['lr'] / 10\n",
    "        # logger.log(f\"Epoch {e+1}\\n-------------------------------\")\n",
    "\n",
    "        if agg_type == \"fedavg\":\n",
    "            clients = random.sample(clients, conf[\"k\"])\n",
    "        \n",
    "        updates = []\n",
    "            \n",
    "        for client in clients:\n",
    "        \n",
    "            update = client.local_train(server.global_model)\n",
    "            updates.append(update)\n",
    "        if m > 0:\n",
    "            uptates = server.get_mal_updates(updates)\n",
    "\n",
    "        server.model_aggregate(updates)\n",
    "        correct, test_loss = server.model_eval()\n",
    "        end = datetime.datetime.now()\n",
    "        logger.log(f\"Time: {(end-start).seconds}s Epoch: {e+1} Learning rate: {conf['lr']} Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \")\n",
    "        if test:\n",
    "            break\n",
    "        \n",
    "        # Save the checkpoint\n",
    "        torch.save([e, server.global_model.state_dict()], chpt_path)\n",
    "    logger.log(\"Complete at %s\" %(datetime.datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab2270ef1f9526990ba4e770b90953b6b57480b197d653547fd8a9b1e0eec128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
